As a final type of model, we tried using neural networks. The best performing one, was a simple neural network trained on the full dataset, having one dense layer of 16 neurons using the relu activation function and an output-layer of one neuron, using the sigmoid activation function to get a probability of the star being a migrator. It was trained using cross entropy as the loss-function and adam as the optimizer. Here we achieved an accuracy of 88\%, called Neural Network 5 in table \ref{tab:RawData}. The rest of the Neural Networks were only trained on the sample data.
\input{Tables/Models}
Of the models only trained on sample data we observe that it is actually the simplest model with only one dense layer with 16 neurons, that performs the best, Neural Network 3, which is why we chose to train a similar neural network on all of the data. It is clear that adding more neurons decreases the testing performance of the model, likely due to overfitting, while it is unclear whether more layers increases or decreases the testing accuracy. It is also worth noting, that using either sigmoid or softmax performs the same.